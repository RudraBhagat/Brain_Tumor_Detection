{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UDPw_pXyAKeS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 150\n",
        "LABELS = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
        "NUM_CLASSES = len(LABELS)\n",
        "# *** REPLACE with the path from your Google Drive ***\n",
        "DATASET_PATH = '/content/drive/MyDrive/Tumor_Detection'"
      ],
      "metadata": {
        "id": "DWU4hFDSAfa_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Starting Data Loading ---\")\n",
        "X = [] # To hold image data\n",
        "Y = [] # To hold labels\n",
        "\n",
        "def load_images_from_folder(base_path, folder_name):\n",
        "    full_path = os.path.join(base_path, folder_name)\n",
        "    if not os.path.exists(full_path):\n",
        "        print(f\"Path not found: {full_path}. Please check your DATASET_PATH.\")\n",
        "        return\n",
        "    for label in LABELS:\n",
        "        folderPath = os.path.join(full_path, label)\n",
        "        print(f\"Loading images from: {folderPath}\")\n",
        "        for j in os.listdir(folderPath):\n",
        "            img_path = os.path.join(folderPath, j)\n",
        "            try:\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "                    X.append(img)\n",
        "                    Y.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Could not load image {img_path}: {e}\")\n",
        "\n",
        "load_images_from_folder(DATASET_PATH, 'Training')\n",
        "load_images_from_folder(DATASET_PATH, 'Testing')\n",
        "\n",
        "print(f\"Total Images Loaded: {len(X)}\")\n",
        "\n",
        "if len(X) == 0:\n",
        "    print(\"No images loaded. Exiting script.\")\n",
        "    exit()\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "X, Y = shuffle(X, Y, random_state=101)\n",
        "\n",
        "# Split into Training (80%), Validation (10%), and Test (10%)\n",
        "X_train_raw, X_test, y_train_raw, y_test_raw = train_test_split(X, Y, test_size=0.1, random_state=101)\n",
        "X_train, X_val, y_train_raw, y_val_raw = train_test_split(\n",
        "    X_train_raw, y_train_raw, test_size=0.1/0.9, random_state=101\n",
        ")\n",
        "\n",
        "def encode_labels(raw_labels):\n",
        "    encoded = [LABELS.index(i) for i in raw_labels]\n",
        "    return tf.keras.utils.to_categorical(encoded, num_classes=NUM_CLASSES)\n",
        "\n",
        "y_train = encode_labels(y_train_raw)\n",
        "y_val = encode_labels(y_val_raw)\n",
        "y_test = encode_labels(y_test_raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj1z0yZ3AiFa",
        "outputId": "6bf47ec8-fcfd-42aa-8a98-a3adbb42e57e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Data Loading ---\n",
            "Loading images from: /content/drive/MyDrive/Tumor_Detection/Training/glioma_tumor\n",
            "Loading images from: /content/drive/MyDrive/Tumor_Detection/Training/meningioma_tumor\n",
            "Loading images from: /content/drive/MyDrive/Tumor_Detection/Training/no_tumor\n",
            "Loading images from: /content/drive/MyDrive/Tumor_Detection/Training/pituitary_tumor\n",
            "Loading images from: /content/drive/MyDrive/Tumor_Detection/Testing/glioma_tumor\n",
            "Loading images from: /content/drive/MyDrive/Tumor_Detection/Testing/meningioma_tumor\n",
            "Loading images from: /content/drive/MyDrive/Tumor_Detection/Testing/no_tumor\n",
            "Loading images from: /content/drive/MyDrive/Tumor_Detection/Testing/pituitary_tumor\n",
            "Total Images Loaded: 3266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Building and Fine-Tuning VGG16 Model ---\")\n",
        "\n",
        "# Load VGG16 without the top layers\n",
        "base_model = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        ")\n",
        "\n",
        "# Freeze the majority of the VGG16 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Unfreeze the last 4 convolutional layers for fine-tuning\n",
        "# This allows the model to learn medical-specific features\n",
        "for layer in base_model.layers[-4:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Construct the full model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model (Use a very low learning rate for fine-tuning)\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), # Lower LR than before!\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "GrQEeAnLAnQL",
        "outputId": "5e461227-e871-4d13-b0d9-97f68131787e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Building and Fine-Tuning VGG16 Model ---\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m4,194,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m2,052\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,911,556\u001b[0m (72.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,911,556</span> (72.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,276,292\u001b[0m (43.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,276,292</span> (43.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,635,264\u001b[0m (29.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,635,264</span> (29.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Setting up Data Generators ---\")\n",
        "\n",
        "# Data Augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Only normalization for validation and test\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create generators\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
        "val_generator = val_test_datagen.flow(X_val, y_val, batch_size=32)\n",
        "test_datagen = val_test_datagen # Use the same normalization for test set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl1LQK6nArhd",
        "outputId": "1a0fd4f1-ec8e-4f4b-b11b-84fd7633c04a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Setting up Data Generators ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Starting Model Training ---\")\n",
        "\n",
        "MODEL_SAVE_PATH = 'brain_tumor_detection_model.keras'\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath=MODEL_SAVE_PATH,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=7, # Increased patience since we are training more robustly\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train the model using the generators\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(X_train) // 32, # Calculate steps based on batch size\n",
        "    epochs=50,                          # Increased epochs for better learning\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(X_val) // 32,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Load and evaluate the best model\n",
        "best_model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
        "\n",
        "# Use the test generator for evaluation (only normalization is applied)\n",
        "loss, accuracy = best_model.evaluate(test_datagen.flow(X_test, y_test, batch_size=32), verbose=0)\n",
        "print(f\"\\n✅ Final Model Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "print(f\"\\nModel saved as '{MODEL_SAVE_PATH}' for UI deployment.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlUYnDGyAu1n",
        "outputId": "26c45800-e358-480f-b9f5-10438a7f15f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Model Training ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.3393 - loss: 1.4403\n",
            "Epoch 1: val_accuracy improved from -inf to 0.69063, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 374ms/step - accuracy: 0.3405 - loss: 1.4382 - val_accuracy: 0.6906 - val_loss: 0.8437\n",
            "Epoch 2/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - accuracy: 0.5312 - loss: 1.1047"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_accuracy improved from 0.69063 to 0.69375, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5312 - loss: 1.1047 - val_accuracy: 0.6938 - val_loss: 0.8309\n",
            "Epoch 3/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6105 - loss: 0.9307\n",
            "Epoch 3: val_accuracy improved from 0.69375 to 0.76562, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 248ms/step - accuracy: 0.6110 - loss: 0.9299 - val_accuracy: 0.7656 - val_loss: 0.6586\n",
            "Epoch 4/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - accuracy: 0.7812 - loss: 0.6147\n",
            "Epoch 4: val_accuracy did not improve from 0.76562\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7812 - loss: 0.6147 - val_accuracy: 0.7656 - val_loss: 0.6555\n",
            "Epoch 5/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.7174 - loss: 0.7129\n",
            "Epoch 5: val_accuracy improved from 0.76562 to 0.81875, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 243ms/step - accuracy: 0.7175 - loss: 0.7127 - val_accuracy: 0.8188 - val_loss: 0.5530\n",
            "Epoch 6/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 110ms/step - accuracy: 0.7188 - loss: 0.7185\n",
            "Epoch 6: val_accuracy did not improve from 0.81875\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7188 - loss: 0.7185 - val_accuracy: 0.8094 - val_loss: 0.5524\n",
            "Epoch 7/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.7748 - loss: 0.5966\n",
            "Epoch 7: val_accuracy improved from 0.81875 to 0.83125, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 242ms/step - accuracy: 0.7749 - loss: 0.5964 - val_accuracy: 0.8313 - val_loss: 0.4899\n",
            "Epoch 8/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - accuracy: 0.7812 - loss: 0.5605\n",
            "Epoch 8: val_accuracy did not improve from 0.83125\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7812 - loss: 0.5605 - val_accuracy: 0.8281 - val_loss: 0.4796\n",
            "Epoch 9/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.8122 - loss: 0.5207\n",
            "Epoch 9: val_accuracy improved from 0.83125 to 0.83438, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 254ms/step - accuracy: 0.8122 - loss: 0.5204 - val_accuracy: 0.8344 - val_loss: 0.4550\n",
            "Epoch 10/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - accuracy: 0.7188 - loss: 0.6669\n",
            "Epoch 10: val_accuracy improved from 0.83438 to 0.83750, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7188 - loss: 0.6669 - val_accuracy: 0.8375 - val_loss: 0.4627\n",
            "Epoch 11/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.8133 - loss: 0.4820\n",
            "Epoch 11: val_accuracy improved from 0.83750 to 0.85938, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 245ms/step - accuracy: 0.8134 - loss: 0.4819 - val_accuracy: 0.8594 - val_loss: 0.4282\n",
            "Epoch 12/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - accuracy: 0.9062 - loss: 0.3382\n",
            "Epoch 12: val_accuracy improved from 0.85938 to 0.86250, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9062 - loss: 0.3382 - val_accuracy: 0.8625 - val_loss: 0.4273\n",
            "Epoch 13/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.8346 - loss: 0.4477\n",
            "Epoch 13: val_accuracy did not improve from 0.86250\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 238ms/step - accuracy: 0.8347 - loss: 0.4474 - val_accuracy: 0.8594 - val_loss: 0.3726\n",
            "Epoch 14/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - accuracy: 0.7188 - loss: 0.6505\n",
            "Epoch 14: val_accuracy did not improve from 0.86250\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7188 - loss: 0.6505 - val_accuracy: 0.8500 - val_loss: 0.3957\n",
            "Epoch 15/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.8480 - loss: 0.4049\n",
            "Epoch 15: val_accuracy improved from 0.86250 to 0.87500, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 273ms/step - accuracy: 0.8481 - loss: 0.4048 - val_accuracy: 0.8750 - val_loss: 0.3591\n",
            "Epoch 16/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - accuracy: 0.7812 - loss: 0.5220\n",
            "Epoch 16: val_accuracy did not improve from 0.87500\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7812 - loss: 0.5220 - val_accuracy: 0.8750 - val_loss: 0.3456\n",
            "Epoch 17/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.8733 - loss: 0.3522\n",
            "Epoch 17: val_accuracy improved from 0.87500 to 0.88125, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 260ms/step - accuracy: 0.8732 - loss: 0.3523 - val_accuracy: 0.8813 - val_loss: 0.3762\n",
            "Epoch 18/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 107ms/step - accuracy: 0.7188 - loss: 0.8041\n",
            "Epoch 18: val_accuracy improved from 0.88125 to 0.88437, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.7188 - loss: 0.8041 - val_accuracy: 0.8844 - val_loss: 0.3848\n",
            "Epoch 19/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.8650 - loss: 0.3347\n",
            "Epoch 19: val_accuracy did not improve from 0.88437\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 236ms/step - accuracy: 0.8650 - loss: 0.3347 - val_accuracy: 0.8844 - val_loss: 0.3457\n",
            "Epoch 20/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.7812 - loss: 0.3955\n",
            "Epoch 20: val_accuracy improved from 0.88437 to 0.90000, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7812 - loss: 0.3955 - val_accuracy: 0.9000 - val_loss: 0.3275\n",
            "Epoch 21/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.8792 - loss: 0.3110\n",
            "Epoch 21: val_accuracy did not improve from 0.90000\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 501ms/step - accuracy: 0.8793 - loss: 0.3109 - val_accuracy: 0.8938 - val_loss: 0.3107\n",
            "Epoch 22/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 108ms/step - accuracy: 0.8750 - loss: 0.2733\n",
            "Epoch 22: val_accuracy did not improve from 0.90000\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8750 - loss: 0.2733 - val_accuracy: 0.8906 - val_loss: 0.3123\n",
            "Epoch 23/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.8993 - loss: 0.2809\n",
            "Epoch 23: val_accuracy did not improve from 0.90000\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 245ms/step - accuracy: 0.8992 - loss: 0.2811 - val_accuracy: 0.8969 - val_loss: 0.3122\n",
            "Epoch 24/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - accuracy: 0.9375 - loss: 0.3328\n",
            "Epoch 24: val_accuracy did not improve from 0.90000\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9375 - loss: 0.3328 - val_accuracy: 0.8969 - val_loss: 0.3078\n",
            "Epoch 25/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.8903 - loss: 0.3010\n",
            "Epoch 25: val_accuracy did not improve from 0.90000\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 252ms/step - accuracy: 0.8905 - loss: 0.3007 - val_accuracy: 0.8875 - val_loss: 0.3416\n",
            "Epoch 26/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 0.9062 - loss: 0.3994\n",
            "Epoch 26: val_accuracy did not improve from 0.90000\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9062 - loss: 0.3994 - val_accuracy: 0.8813 - val_loss: 0.3439\n",
            "Epoch 27/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9063 - loss: 0.2322\n",
            "Epoch 27: val_accuracy did not improve from 0.90000\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 254ms/step - accuracy: 0.9062 - loss: 0.2325 - val_accuracy: 0.9000 - val_loss: 0.3102\n",
            "Epoch 28/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9375 - loss: 0.1942\n",
            "Epoch 28: val_accuracy did not improve from 0.90000\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9375 - loss: 0.1942 - val_accuracy: 0.8844 - val_loss: 0.3580\n",
            "Epoch 29/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9134 - loss: 0.2342\n",
            "Epoch 29: val_accuracy did not improve from 0.90000\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 230ms/step - accuracy: 0.9134 - loss: 0.2343 - val_accuracy: 0.9000 - val_loss: 0.3421\n",
            "Epoch 30/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - accuracy: 0.8750 - loss: 0.2516\n",
            "Epoch 30: val_accuracy improved from 0.90000 to 0.90312, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8750 - loss: 0.2516 - val_accuracy: 0.9031 - val_loss: 0.3344\n",
            "Epoch 31/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.9179 - loss: 0.2402\n",
            "Epoch 31: val_accuracy did not improve from 0.90312\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 232ms/step - accuracy: 0.9179 - loss: 0.2401 - val_accuracy: 0.8969 - val_loss: 0.2835\n",
            "Epoch 32/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - accuracy: 0.9062 - loss: 0.2157\n",
            "Epoch 32: val_accuracy did not improve from 0.90312\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9062 - loss: 0.2157 - val_accuracy: 0.9000 - val_loss: 0.2768\n",
            "Epoch 33/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9285 - loss: 0.2042\n",
            "Epoch 33: val_accuracy improved from 0.90312 to 0.90625, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 244ms/step - accuracy: 0.9285 - loss: 0.2042 - val_accuracy: 0.9062 - val_loss: 0.2989\n",
            "Epoch 34/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 111ms/step - accuracy: 0.9062 - loss: 0.3036\n",
            "Epoch 34: val_accuracy did not improve from 0.90625\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9062 - loss: 0.3036 - val_accuracy: 0.9062 - val_loss: 0.2983\n",
            "Epoch 35/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.9269 - loss: 0.1963\n",
            "Epoch 35: val_accuracy did not improve from 0.90625\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 233ms/step - accuracy: 0.9269 - loss: 0.1963 - val_accuracy: 0.9062 - val_loss: 0.2871\n",
            "Epoch 36/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - accuracy: 0.8750 - loss: 0.3747\n",
            "Epoch 36: val_accuracy improved from 0.90625 to 0.90938, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8750 - loss: 0.3747 - val_accuracy: 0.9094 - val_loss: 0.2766\n",
            "Epoch 37/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9309 - loss: 0.1872\n",
            "Epoch 37: val_accuracy did not improve from 0.90938\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 246ms/step - accuracy: 0.9309 - loss: 0.1872 - val_accuracy: 0.9031 - val_loss: 0.2693\n",
            "Epoch 38/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - accuracy: 0.9062 - loss: 0.2012\n",
            "Epoch 38: val_accuracy did not improve from 0.90938\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9062 - loss: 0.2012 - val_accuracy: 0.9062 - val_loss: 0.2638\n",
            "Epoch 39/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9321 - loss: 0.1744\n",
            "Epoch 39: val_accuracy improved from 0.90938 to 0.91250, saving model to brain_tumor_detection_model.keras\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 246ms/step - accuracy: 0.9321 - loss: 0.1743 - val_accuracy: 0.9125 - val_loss: 0.2754\n",
            "Epoch 40/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 108ms/step - accuracy: 0.8750 - loss: 0.3036\n",
            "Epoch 40: val_accuracy did not improve from 0.91250\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8750 - loss: 0.3036 - val_accuracy: 0.9031 - val_loss: 0.2751\n",
            "Epoch 41/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9323 - loss: 0.1801\n",
            "Epoch 41: val_accuracy did not improve from 0.91250\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 270ms/step - accuracy: 0.9323 - loss: 0.1800 - val_accuracy: 0.9125 - val_loss: 0.2761\n",
            "Epoch 42/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - accuracy: 0.9375 - loss: 0.2064\n",
            "Epoch 42: val_accuracy did not improve from 0.91250\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9375 - loss: 0.2064 - val_accuracy: 0.9031 - val_loss: 0.2957\n",
            "Epoch 43/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9446 - loss: 0.1686\n",
            "Epoch 43: val_accuracy did not improve from 0.91250\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 236ms/step - accuracy: 0.9445 - loss: 0.1687 - val_accuracy: 0.8969 - val_loss: 0.3232\n",
            "Epoch 44/50\n",
            "\u001b[1m 1/81\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9375 - loss: 0.1460\n",
            "Epoch 44: val_accuracy did not improve from 0.91250\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9375 - loss: 0.1460 - val_accuracy: 0.9000 - val_loss: 0.3125\n",
            "Epoch 45/50\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9514 - loss: 0.1472\n",
            "Epoch 45: val_accuracy did not improve from 0.91250\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 247ms/step - accuracy: 0.9514 - loss: 0.1471 - val_accuracy: 0.9125 - val_loss: 0.2946\n",
            "\n",
            "✅ Final Model Test Accuracy: 92.97%\n",
            "\n",
            "Model saved as 'brain_tumor_detection_model.keras' for UI deployment.\n"
          ]
        }
      ]
    }
  ]
}